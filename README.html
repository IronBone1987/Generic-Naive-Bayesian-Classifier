A Python implementation of a Naive Bayesian Classifier.

Written as generic as possible. The database currently uses Sqlite3 but the NaiveBayesDB can subclassed to use another database if so desired.

Example training usage for spam filtering:

<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span style="color: #f92672">from</span> <span style="color: #f8f8f2">naive_bayes_classifier</span> <span style="color: #f92672">import</span> <span style="color: #f8f8f2">NaiveBayesClassifier</span>
<span style="color: #f92672">from</span> <span style="color: #f8f8f2">example_tokenizer</span> <span style="color: #f92672">import</span> <span style="color: #f8f8f2">SpamTokenizer</span>

<span style="color: #75715e"># sqlite3 database file to be created does not exist</span>
<span style="color: #f8f8f2">SPAM_CLASSIFIER_DB</span> <span style="color: #f92672">=</span> <span style="color: #e6db74">&#39;/path/to/spam_classifier.db&#39;</span>
<span style="color: #75715e"># to train positive:</span>
<span style="color: #f8f8f2">spam</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">SpamTokenizer(raw_data)</span> <span style="color: #75715e"># process tokens from raw data</span>
<span style="color: #f8f8f2">spam</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">tokenize()</span> <span style="color: #75715e"># returns a list of tokens </span>

<span style="color: #75715e"># assuming an existing database; see class to add description</span>
<span style="color: #75715e"># to the database.</span>
<span style="color: #f8f8f2">spam_bayes</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">NaiveBayesClassifier(SPAM_CLASSIFIER_DB)</span>
<span style="color: #f8f8f2">spam_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">register_tokens(spam</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">tokens)</span>
<span style="color: #f8f8f2">spam_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">train_positive()</span>

<span style="color: #75715e"># train negative</span>
<span style="color: #f8f8f2">non_spam</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">SpamTokenizer(non_spam_raw_data)</span>
<span style="color: #f8f8f2">non_spam</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">tokenize()</span>
<span style="color: #f8f8f2">spam_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">register_tokens(non_spam</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">tokens)</span>
<span style="color: #f8f8f2">spam_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">train_negative()</span>

<span style="color: #75715e"># Example testing usage, for spam email testing:</span>
<span style="color: #f8f8f2">test_email</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">open(</span><span style="color: #e6db74">&#39;/path/to/test.eml&#39;</span><span style="color: #f8f8f2">)</span>
<span style="color: #f8f8f2">test</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">SpamTokenizer(test_email)</span>
<span style="color: #f8f8f2">test</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">tokenize()</span>

<span style="color: #f8f8f2">spam_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">register_tokens(test</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">tokens)</span>
<span style="color: #f8f8f2">spam_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">caclulate_probabilities()</span>

<span style="color: #75715e"># show results above token list</span>
<span style="color: #66d9ef">print</span><span style="color: #f8f8f2">(</span><span style="color: #e6db74">&quot;%.6f positive %.6f negative </span><span style="color: #ae81ff">\n</span><span style="color: #e6db74"> %s </span><span style="color: #ae81ff">\n</span><span style="color: #e6db74">&quot;</span> <span style="color: #f92672">%</span> <span style="color: #f8f8f2">(subject_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">sum_positive(),</span>
                                                <span style="color: #f8f8f2">subject_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">sum_negative(),</span>
                                                <span style="color: #f8f8f2">[x</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">token_string</span> <span style="color: #66d9ef">for</span> <span style="color: #f8f8f2">x</span> <span style="color: #f92672">in</span> <span style="color: #f8f8f2">subject_bayes</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">tokens]))</span>
</pre></div>

Background:
Bayes Therom
P(A|B) = (P(B|A)*P(A))/P(B)

The probability of A given B is equal to the probability of B given A multiplied by the probability of A, divided over the probability of B.

A naive bayesian classifier formula

P(S|W) = P(W|S) / ( P(W|S) + P(W|H) )

The probability of a word being spammy, S, given a word, W, is equal to the probability of the frequency of word occurance in all spam messages in the training data, P(W|S)[if there were 300 messages marked spam and 25 occurances of the word 'purchase', the probability would be 25/300=.083], divided by the sum of P(W|S) and the frequency of word occurances in all ham messages in the training data, P(W|H).
----
Combining individual probabilities

p(S) = (p1 * p2 ... pn) / ( (p1 * p2 ... * pn) + ( (1 - p1) * (1 - p2) ... * (1 - pn) ) )

The formula for summing the probability of a message being labeled as spam, p(S), is equal to the product of each word's probability of being spammy, p1 through pn, divided by the sum of products p1 through pn and the products (1 - p1) through (1 - pn).

Python used to create Sqlite3 database:

<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span style="color: #f8f8f2">cursor</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">execute(</span><span style="color: #e6db74">&quot;create table counters (counter INTEGER, name TEXT, description TEXT)&quot;</span><span style="color: #f8f8f2">)</span>
<span style="color: #f8f8f2">cursor</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">execute(</span><span style="color: #e6db74">&quot;insert into counters VALUES (0, &#39;global_counter&#39;, ?)&quot;</span><span style="color: #f8f8f2">,</span> <span style="color: #f8f8f2">(global_description,))</span>
<span style="color: #f8f8f2">cursor</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">execute(</span><span style="color: #e6db74">&quot;insert into counters VALUES (0, &#39;positive_counter&#39;, ?)&quot;</span><span style="color: #f8f8f2">,</span> <span style="color: #f8f8f2">(positive_description,))</span>
<span style="color: #f8f8f2">cursor</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">execute(</span><span style="color: #e6db74">&quot;insert into counters VALUES (0, &#39;negative_counter&#39;, ?)&quot;</span><span style="color: #f8f8f2">,</span> <span style="color: #f8f8f2">(negative_description,))</span>
<span style="color: #f8f8f2">cursor</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">execute(</span><span style="color: #e6db74">&quot;create table negative_classification (token TEXT UNIQUE, count INTEGER)&quot;</span><span style="color: #f8f8f2">)</span>
<span style="color: #f8f8f2">cursor</span><span style="color: #f92672">.</span><span style="color: #f8f8f2">execute(</span><span style="color: #e6db74">&quot;create table positive_classification (token TEXT UNIQUE, count INTEGER)&quot;</span><span style="color: #f8f8f2">)</span>
</pre></div>


